{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2589b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib as mpl\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt\n",
    "import functools\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from scipy import stats as scpstats\n",
    "import random\n",
    "\n",
    "from shapely.geometry import LineString\n",
    "from matplotlib.ticker import FixedLocator, FixedFormatter,AutoMinorLocator\n",
    "\n",
    "from scipy import interpolate \n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08804e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_numpy(df):\n",
    "    df=df.astype(float)\n",
    "    df=df.T\n",
    "    df=df.to_numpy()\n",
    "    return(df)\n",
    "\n",
    "def FiringRateBis(spiketrain, inf, sup):\n",
    "    xx = np.arange(inf, sup, 0.001)\n",
    "    yy = np.zeros_like(xx)\n",
    "    for spike in spiketrain:\n",
    "        yy += scpstats.norm.pdf(xx, loc=spike, scale=0.05) #bandwidth de 50 ms\n",
    "    return(xx,yy)\n",
    "def format_axes(ax,xlabel,ylabel, reffig, loclegend, pos='right',color='black'):\n",
    "    ax.text(reffig[0], reffig[1], reffig[2], fontsize=reffig[3], fontweight=\"bold\", transform=ax.transAxes)\n",
    "    ax.spines[pos].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.set_xlabel(xlabel, fontsize=8)\n",
    "    ax.set_ylabel(ylabel, fontsize=8, color=color)\n",
    "    ax.tick_params(axis='x', labelsize=8)\n",
    "    ax.tick_params(axis='y', labelsize=8)\n",
    "\n",
    "\n",
    "def intersect2(v, R):    \n",
    "    \n",
    "    T1=-extract_flow_velo(v,R)[0]/min(extract_flow_velo(v,R)[0])\n",
    "    L1=extract_flow_velo(v,R)[1]\n",
    "    \n",
    "    l1=np.column_stack((T1[:len(L1.dropna())],L1.dropna()))\n",
    "    l2=np.column_stack((T1[:len(L1.dropna())],np.repeat(mean_thres,len(l1)) ))\n",
    "\n",
    "    firstline=LineString(l1)\n",
    "    secondline = LineString(l2)   \n",
    "    \n",
    "    intersectionA = firstline.intersection(secondline)\n",
    "    vth=intersectionA.xy[0][0]\n",
    "    pth=100-abs(vth)*100\n",
    "    \n",
    "    return(pth)\n",
    "\n",
    "def return_velo(V,r,interp=False):\n",
    "    NTIMES=101\n",
    "    string= \"R\"+ str(r)+\"_v\"+str(V)\n",
    "    T=Vitesses_dico[string] #Rechercher clé dans le dico\n",
    "    X0=np.linspace(0,6/V,NTIMES) #axs[j].plot(np.linspace(0,6/V,NTIMES),T[:,NPOSES//2],label=str(V))\n",
    "    X=X0-4/V #mise à zéro\n",
    "    idx=np.min(np.argwhere(X > 0))\n",
    "    \n",
    "    if interp==True:\n",
    "        tCFD,fCFD=X[:idx+1],T.loc[:idx]\n",
    "        indices = np.logical_not(np.isnan(np.asarray(fCFD))).flatten()\n",
    "        tCFD = np.asarray(tCFD)[indices]\n",
    "        fCFD = np.asarray(fCFD)[indices].squeeze()\n",
    "        temp = interpolate.interp1d(tCFD, fCFD, fill_value=\"extrapolate\") \n",
    "        xnew = np.arange(np.nanmin(X[:idx+1]), 0,0.0001)\n",
    "        ynew = temp(xnew) \n",
    "        return(xnew,ynew)\n",
    "    \n",
    "    else:\n",
    "        return(X[:idx+1],T.loc[:idx] )\n",
    "\n",
    "def intersect(line1,line2):    \n",
    "    firstline=LineString(line1)\n",
    "    secondline = LineString(line2)   \n",
    "    try:\n",
    "        intersectionA = firstline.intersection(secondline)\n",
    "        vth=intersectionA.xy[1][0]\n",
    "    except:\n",
    "        vth=np.nan\n",
    "    return(vth)\n",
    "\n",
    "def intersect_th(v, R): \n",
    "    T1=extract_flow_velo(v,R)[0]\n",
    "    L1=extract_flow_velo(v,R)[1]\n",
    "    \n",
    "    l1=np.column_stack((T1[:len(L1.dropna())],L1.dropna()))\n",
    "    l2=np.column_stack((T1[:len(L1.dropna())],np.repeat(mean_thres,len(l1)) ))\n",
    "\n",
    "    firstline=LineString(l1)\n",
    "    secondline = LineString(l2)   \n",
    "    \n",
    "    intersectionA = firstline.intersection(secondline)\n",
    "    try:\n",
    "        vth=intersectionA.xy[0][0]\n",
    "    except:\n",
    "        vth=np.nan\n",
    "    return(vth*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b052dde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vitesses_dico ={}\n",
    "Vitesses_dico[\"R7.5_v5\"]  =pd.read_csv(\"Volumes/2_Volume_R7.5_V5.csv\",header=None)\n",
    "Vitesses_dico[\"R7.5_v10\"] =pd.read_csv(\"Volumes/2_Volume_R7.5_V10.csv\",header=None)\n",
    "Vitesses_dico[\"R7.5_v20\"] =pd.read_csv(\"Volumes/2_Volume_R7.5_V20.csv\",header=None)\n",
    "Vitesses_dico[\"R7.5_v40\"] =pd.read_csv(\"Volumes/2_Volume_R7.5_V40.csv\",header=None)\n",
    "Vitesses_dico[\"R15_v5\"] =pd.read_csv(\"Volumes/2_Volume_R15_V5.csv\",header=None)\n",
    "Vitesses_dico[\"R15_v10\"]=pd.read_csv(\"Volumes/2_Volume_R15_V10.csv\",header=None)\n",
    "Vitesses_dico[\"R15_v20\"]=pd.read_csv(\"Volumes/2_Volume_R15_V20.csv\",header=None)\n",
    "Vitesses_dico[\"R15_v40\"]=pd.read_csv(\"Volumes/2_Volume_R15_V40.csv\",header=None)\n",
    "Vitesses_dico[\"R25_v5\"] =pd.read_csv(\"Volumes/2_Volume_R25_V5.csv\",header=None)\n",
    "Vitesses_dico[\"R25_v10\"]=pd.read_csv(\"Volumes/2_Volume_R25_V10.csv\",header=None)\n",
    "Vitesses_dico[\"R25_v20\"]=pd.read_csv(\"Volumes/2_Volume_R25_v20.csv\",header=None)\n",
    "Vitesses_dico[\"R25_v40\"]=pd.read_csv(\"Volumes/2_Volume_R25_v40.csv\",header=None)\n",
    "\n",
    "\n",
    "df_final = pd.concat(pd.read_excel('Treadmill_clean.xlsx', sheet_name=None), ignore_index=True)\n",
    "df_final=df_final.loc[(df_final['keep'] == 1) ]\n",
    "df_final['treac']=df_final['frames_reac']*0.002\n",
    "df_final_new=df_final\n",
    "df_final_new['dreac']=df_final_new['v']*df_final_new['treac']-4\n",
    "df_final_new['treac2'] = df_final_new['treac'] - 4/df_final_new['v']\n",
    "df_final_new['R_div_v']=df_final_new['R']*0.01/df_final_new['v']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb530032",
   "metadata": {},
   "source": [
    "# 1. Extract Behavioural Delays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3052f71",
   "metadata": {},
   "source": [
    "Outputs:  \n",
    "- A csv file \n",
    "- A pdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97baf7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BehavFile:\n",
    "    def __init__(self,index):\n",
    "        self.index = index \n",
    "        DF=df_final_new\n",
    "        self.experiment= DF.loc[(DF['idx'] == index)]\n",
    "        self.tail=self.experiment['idx'].iloc[0]\n",
    "        self.size=int(self.experiment['R'].iloc[0])/10\n",
    "        if self.size !=7.5:\n",
    "            self.size=int(self.size)\n",
    "    def extract_valves(self, plotting):\n",
    "        \n",
    "        self.LINES=[]\n",
    "        self.LIST_TPEAK=[]\n",
    "        \n",
    "        \n",
    "        self.tab=pd.DataFrame(columns=['file','v','R','treac']) #,'FR_pre'\n",
    "\n",
    "        t40,f40=return_velo(40,self.size,interp=True)\n",
    "        t20,f20=return_velo(20,self.size,interp=True)\n",
    "        t10,f10=return_velo(10,self.size,interp=True)\n",
    "        t05,f05=return_velo(5, self.size,interp=True)\n",
    "        simvelo=[f40,f20,f10,f05]\n",
    "        simtime=[t40,t20,t10,t05]\n",
    "        velocities=[40,20,10,5]\n",
    "        colors=['tab:blue','tab:orange','tab:green','tab:red']\n",
    "        \n",
    "        stim=np.log2(40/self.experiment['v'])\n",
    "        stim=[s if np.floor(s)==s else 4.0 for s in stim]\n",
    "\n",
    "\n",
    "        if plotting:\n",
    "            fig,ax = plt.subplots(figsize=(6,12))\n",
    "            ax0=plt.subplot2grid((6,1),(0,0))\n",
    "            ax5=plt.subplot2grid((6,1),(1,0))\n",
    "            ax6=plt.subplot2grid((6,1),(2,0))\n",
    "            ax7=plt.subplot2grid((6,1),(3,0))\n",
    "            ax8=plt.subplot2grid((6,1),(4,0))\n",
    "            #ax1B=plt.subplot2grid((6,1),(5,0))\n",
    "            axscopy=[ax5,ax6,ax7,ax8]\n",
    "\n",
    "        \n",
    "        regpts=np.zeros((4,1))\n",
    "        self.LABELS=[]\n",
    "        for j in range(4): #0,1,2,3 mais pas 4\n",
    "            ID=int(stim[j])\n",
    "            expe_vitesse= self.experiment.iloc[stim.index(ID)]\n",
    "            \n",
    "            if plotting: \n",
    "                ax0.plot(simtime[ID],simvelo[ID],color=colors[ID])\n",
    "                axscopy[ID].vlines(expe_vitesse['treac2'],0,np.nanmax(simvelo[ID]), linestyle='dashed',color='grey')\n",
    "                axscopy[ID].plot(simtime[ID],simvelo[ID],color=colors[ID])\n",
    "\n",
    "                \n",
    "            self.LABELS+=[velocities[ID]]    #ordre des vitesses\n",
    "            line1=np.column_stack((simtime[ID],simvelo[ID]))\n",
    "            line2=np.column_stack((np.repeat(expe_vitesse['treac2'],len(simvelo[ID])),np.linspace(0,1e-7,len(simvelo[ID]))))\n",
    "            #vth=intersect(line1,line2)\n",
    "                    \n",
    "            self.LINES+=[line1]\n",
    "            #self.LIST_VTH+=[vth]\n",
    "            self.LIST_TPEAK+=[expe_vitesse['treac2']]\n",
    "                    \n",
    "                    \n",
    "            new_row = {'file': self.tail, 'R':self.size,'v': 5*2**abs((3-ID)),'treac':expe_vitesse['treac2'] }\n",
    "            self.tab=pd.concat([self.tab, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "            \n",
    "def find_threshold_v1(S,ax): #filtrage\n",
    "\n",
    "    T=pd.DataFrame(columns=['time','m','b','S','pval','R2','adjR','mu','NPTS','TPTS','residuals','keeppoints','var'])\n",
    "\n",
    "    for delta in np.linspace(0,0.2,500):\n",
    "        Y=[]\n",
    "        X=[]\n",
    "        for k in range(len(S.LINES)):\n",
    "            l1=S.LINES[k]\n",
    "            l2=np.column_stack((np.repeat(S.LIST_TPEAK[k]-delta,len(l1)),np.linspace(0,0.401e-7,len(l1))))\n",
    "            vth=intersect(l1,l2)\n",
    "\n",
    "            X+=[S.LIST_TPEAK[k]-delta]\n",
    "            Y+=[vth]\n",
    "        lentotalpoints=len(X)\n",
    "        indices = np.logical_not(np.logical_or(np.isnan(X), np.isnan(Y)))\n",
    "        X = np.array(X)[indices]\n",
    "        Y = np.array(Y)[indices]\n",
    "\n",
    "        try:\n",
    "            X2 = sm.add_constant(X)\n",
    "            model = sm.OLS(Y, X2)\n",
    "            results = model.fit()\n",
    "            influence = results.get_influence()\n",
    "            standardized_residuals = abs(influence.resid_studentized_internal)\n",
    "        except:\n",
    "            standardized_residuals = np.nan\n",
    "\n",
    "        try:\n",
    "            X2 = sm.add_constant(X)\n",
    "            model = sm.OLS(Y, X2)\n",
    "            results = model.fit()\n",
    "            influence = results.get_influence()\n",
    "            standardized_residuals = abs(influence.resid_studentized_internal)\n",
    "        except:\n",
    "            standardized_residuals = np.nan\n",
    "\n",
    "        try:\n",
    "            b,m=results.params #attention ordre inversé\n",
    "            pval=results.pvalues[1]\n",
    "            adjR=results.rsquared_adj\n",
    "            R2=results.rsquared\n",
    "        except: \n",
    "            b,m=np.nan,np.nan #attention ordre inversé\n",
    "            pval=np.nan\n",
    "            adjR=np.nan\n",
    "            R2=np.nan\n",
    "        mu=np.mean(Y)\n",
    "        SUM=0\n",
    "        for vth in Y:\n",
    "            SUM+= (vth - mu)**2\n",
    "\n",
    "        if len(X)>0:\n",
    "            SUM=np.sqrt(SUM/len(X))      #RMSE\n",
    "        else:\n",
    "            SUM=np.nan\n",
    "            #print('error')\n",
    "\n",
    "        new_row = {'time':delta,'m':m,'b':b,'S':SUM,'pval':pval,'R2':R2,'adjR':adjR,'mu':mu,'NPTS':len(X),'TPTS':lentotalpoints, 'residuals':standardized_residuals, 'keeppoints': np.sum(standardized_residuals<3), 'var':np.sqrt(np.var(Y))}\n",
    "        T=pd.concat([T, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "    try:\n",
    "        TBIS=T.loc[T['NPTS']==max(T['NPTS'])]\n",
    "        K=T.iloc[abs(TBIS['S']).idxmin()]\n",
    "    except:\n",
    "        try:\n",
    "            K=T.iloc[abs(T['S']).idxmin()]\n",
    "        except:\n",
    "            K=T.iloc[-1]\n",
    "        print('pbm')\n",
    "\n",
    "\n",
    "    LENGTH=np.arange(0,len(S.LINES),1)\n",
    "    VTH=[]\n",
    "\n",
    "\n",
    "    for k,j in zip(LENGTH,S.LABELS):\n",
    "\n",
    "        if S.size==25:\n",
    "            color='tab:green'\n",
    "        elif S.size==15:\n",
    "            color='tab:orange'\n",
    "        else:\n",
    "            color='tab:blue'\n",
    "\n",
    "\n",
    "        if j==40:\n",
    "            marker=\"$40$\"\n",
    "        elif j==20:\n",
    "            marker=\"$20$\"\n",
    "        elif j==10:\n",
    "            marker=\"$10$\"\n",
    "        else:\n",
    "            marker=\"$05$\"\n",
    "\n",
    "\n",
    "        #ax.plot(S.LINES[k][:,0],S.LINES[k][:,1],color='grey')\n",
    "        ax.plot(S.LINES[k][:,0],S.LINES[k][:,1],alpha=0.2,color=color)\n",
    "        l1=S.LINES[k]\n",
    "        l2=np.column_stack((np.repeat(S.LIST_TPEAK[k]-K['time'],len(l1)),np.linspace(0,0.401e-7,len(l1))))\n",
    "        vth=intersect(l1,l2)\n",
    "        VTH+=[vth]\n",
    "        ax.scatter(S.LIST_TPEAK[k]-K['time'],vth,label='v'+str(j)+'_D'+str(S.size),color=color,marker=marker)\n",
    "        ax.scatter(S.LIST_TPEAK[k]-K['time'],vth,color='grey',alpha=0.1)\n",
    "\n",
    "    VTH=np.array([v for v in VTH if str(v) != 'nan'])\n",
    "    ax.hlines(VTH.mean(),-0.8,0,color='grey',linestyle='dashed')\n",
    "    ax.set_title(str(K['NPTS'])+'/'+str(K['TPTS'])+' pts'+'___'+'RMSE:'+\n",
    "                 str(np.round(K['S']*1e8,5))+'e-8'+'___'+r'$\\delta$ ='+str(np.round(K['time']*1e3,1)))\n",
    "    ax.set_ylim([0,0.6e-7])\n",
    "    ax.set_xlabel('time (s)')\n",
    "    ax.set_ylabel('Linear Momentum')\n",
    "    ax.legend(loc='best')\n",
    "    return(T,K)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87195046",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigtab=pd.DataFrame(columns=['file','v','R','maxFR','timingFR','spikes','stimulus','repet','delta','m','S','pval','R2','adjR','mu','NPTS','TPTS','residuals','keeppoints','var'])\n",
    "\n",
    "pp = PdfPages('behavioural_delays_test.pdf')\n",
    "\n",
    "I1=df_final_new.loc[(df_final_new['R'] == 75) & (df_final_new['v'] == 40),'idx']\n",
    "I2=df_final_new.loc[(df_final_new['R'] == 150) & (df_final_new['v'] == 40),'idx']\n",
    "I3=df_final_new.loc[(df_final_new['R'] == 250) & (df_final_new['v'] == 40),'idx']\n",
    "\n",
    "\n",
    "indexes=pd.concat((I1,I2,I3))\n",
    "\n",
    "\n",
    "\n",
    "for k in range(len(indexes)): #len(valves_files)\n",
    "\n",
    "    \n",
    "\n",
    "    S=BehavFile(indexes.iloc[k])\n",
    "    S.extract_valves(False)\n",
    "\n",
    "\n",
    "    fig,ax=plt.subplots(figsize=(8,8))\n",
    "    T1,K=find_threshold_v1(S,ax)\n",
    "    fig.suptitle(df_final_new.loc[df_final_new['idx']==indexes.iloc[k],'vidéo'].iloc[0][31:31+13])\n",
    "    plt.show()\n",
    "    pp.savefig(fig)\n",
    "    \n",
    "    S.tab[['delta','m','S','pval','R2','adjR','mu','NPTS','TPTS','keeppoints','var']]=K[['time','m','S','pval','R2','adjR','mu','NPTS','TPTS','keeppoints','var']]\n",
    "    try:\n",
    "        res = ','.join(str(x) for x in K['residuals'])\n",
    "        S.tab['residuals']= res\n",
    "    except:\n",
    "        pass\n",
    "    bigtab=pd.concat([bigtab, S.tab], ignore_index=True)\n",
    "\n",
    "\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb875b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE THE DATA\n",
    "\n",
    "bigtab2=bigtab.copy()\n",
    "replacements = {75:7, 150: int(15), 250: int(30)}\n",
    "bigtab2['R'] = bigtab2['R'].map(replacements).fillna(bigtab2['R'])\n",
    "bigtab2['R'].astype(int) \n",
    "\n",
    "bigtab2.to_csv('delay_behaviour.csv', sep=',') #[['file','v','R','maxFR','timingFR','spikes']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa02401",
   "metadata": {},
   "source": [
    "# 2 Compare delays and momentums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139e1ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_frame(CLUS):\n",
    "\n",
    "    df=pd.DataFrame(columns=['D','delay','Mth','S','keep']) #'file',\n",
    "\n",
    "    I=0\n",
    "    for t in range(len(CLUS)):\n",
    "        if t%4==0:\n",
    "\n",
    "            \n",
    "   \n",
    "            signif=1 if CLUS[\"S\"].iloc[t]*1e8<=0.5 and CLUS[\"TPTS\"].iloc[t]==CLUS[\"NPTS\"].iloc[t] else 0    \n",
    "            if CLUS[\"delta\"].iloc[t]==0.2:\n",
    "                signif=0\n",
    "    \n",
    "                \n",
    "                \n",
    "            new_row = {#'file':I, #'$'+CLUS[\"file\"].iloc[t]+'$'\n",
    "                'D':CLUS[\"R\"].iloc[t],\n",
    "                           'delay':CLUS[\"delta\"].iloc[t] if CLUS[\"delta\"].iloc[t]!=0 else np.nan ,\n",
    "                           'Mth': CLUS[\"mu\"].iloc[t],\n",
    "                       'S':CLUS[\"S\"].iloc[t],\n",
    "                        'keep': signif\n",
    "                      }\n",
    "            df=pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)    \n",
    "\n",
    "    df=df.rename(columns={'D': \"D\",\n",
    "                          'delay': \"$\\delta^b$\",\n",
    "                       'Mth': \"$M_{th}^n$\",\n",
    "                        'S':\"$10^{8}*M_{th}$\",\n",
    "                        'keep': \"keep\"})\n",
    "    \n",
    "    #df=df.dropna()\n",
    "    \n",
    "    \n",
    "    print('\\\\begin{Stable}')\n",
    "    print(df.to_latex(float_format=\"%.3e\"))\n",
    "    print('\\\\caption{Behavioral threshold analysis}')\n",
    "    print('\\\\label{tab:beh_vth}')\n",
    "    print('\\\\end{Stable}')\n",
    "    return(df)\n",
    "\n",
    "def return_color_code(R,v):\n",
    "    if R==7.5:\n",
    "        color='tab:blue'\n",
    "    elif R==15:\n",
    "        color='tab:orange'\n",
    "    else:\n",
    "        color='tab:green'\n",
    "        \n",
    "    if v==40:\n",
    "        style='dashed'\n",
    "    elif v==20:\n",
    "        style='solid'\n",
    "    elif v==10:\n",
    "        style='dotted'\n",
    "    else:\n",
    "        style=(0, (3, 5, 1, 5))\n",
    "    return(color,style)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46380d76",
   "metadata": {},
   "source": [
    "## 2.1. Data to Latex Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7c2298",
   "metadata": {},
   "outputs": [],
   "source": [
    "T0=pd.read_csv('delay_behaviour.csv')\n",
    "DF=data_frame(T0)\n",
    "DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a9acfc",
   "metadata": {},
   "source": [
    "## 2.2 Plots delays and momentums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40556ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_bar_delay(DF,ax,color,label,strict, coeff=1):\n",
    "    \n",
    "    ax.scatter(coeff*DF.loc[DF[\"keep\"].astype(int)>=0,\"$\\delta^b$\"],DF.loc[DF[\"keep\"].astype(int)>=0,\"$10^{8}*M_{th}$\"],color='grey',alpha=0.15,marker='x')\n",
    "    \n",
    "    if strict==True:\n",
    "        DATA=DF.loc[DF[\"keep\"].astype(int)>0]\n",
    "    else:\n",
    "         DATA=DF.loc[DF[\"keep\"].astype(int)>=0]\n",
    "            \n",
    "    ax.scatter(coeff*DATA[\"$\\delta^b$\"],DATA[\"$10^{8}*M_{th}$\"], marker='x', color=color)\n",
    "    #ax.scatter(coeff*DATA[\"$\\delta^n$\"],DATA[\"$10^{8}*M_{th}$\"], color=color, alpha=0.2)\n",
    "    \n",
    "    mean_delay=coeff*np.nanmean(DATA[\"$\\delta^b$\"])\n",
    "    mean_thres=np.nanmean(DATA[\"$10^{8}*M_{th}$\"])\n",
    "    error_delay= coeff*np.nanstd(DATA[\"$\\delta^b$\"])#/len(DF3[\"$\\delta^n$\"])\n",
    "    error_thres= np.nanstd(DATA[\"$10^{8}*M_{th}$\"])\n",
    "    ax.scatter(mean_delay, mean_thres, s=30,label=label, facecolors='none', edgecolors=color)\n",
    "    ax.scatter(mean_delay, mean_thres, s=30, color=color, alpha=0.75)\n",
    "    ax.hlines(mean_thres, mean_delay-error_delay, mean_delay+error_delay, color=color)\n",
    "    ax.vlines(mean_delay, mean_thres-error_thres, mean_thres+error_thres, color=color)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
